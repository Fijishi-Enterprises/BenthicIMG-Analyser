.. _file_serving:

File serving - Media files, static files, and S3
================================================

This page covers serving of media files and static files.


S3 bucket setup
---------------
- *Production/staging*
- *Local server with S3 storage*


.. _s3_bucket_setup:

Setup steps
...........

- Go to the Amazon S3 console.
- Create a bucket.
- Click your bucket's name, then click Properties, then Permissions.
- Click "Add CORS Configuration" and accept the default configuration.
- Click "Add bucket policy" and add the following policy, replacing ``<bucket-name>`` with your bucket's name and ``<mydomain.com>`` with your website's domain name:

::

  {
    "Version": "2012-10-17",
    "Statement": [
      {
        "Sid": "Allow referral from my domains",
        "Effect": "Allow",
        "Principal": "*",
        "Action": "s3:GetObject",
        "Resource": "arn:aws:s3:::<bucket-name>/*",
        "Condition": {
          "StringLike": {
            "aws:Referer": "http://<mydomain.com>/*"
          }
        }
      }
    ]
  }


Explanation on setup steps
..........................

The default CORS configuration should allow any website domain to include bucket objects in their webpages, provided that they have read access to those bucket objects in the first place. CORS is required because our actual website isn't on S3; therefore including an S3 resource on our website is cross-origin sharing.

The above bucket policy defines how the bucket objects can be accessed. It says that, if a bucket object is linked to from the given referer website, that object can always be read. In other cases, as long as our website code only writes S3 ACLs with private permissions, access is restricted to (1) the bucket-owning AWS account, and to (2) IAM users as defined in the IAM console.

This bucket policy prevents hotlinking to S3 images, meaning that if a user just types an image URL into their address bar, they will be denied access. For example, if a user sees an example patch from a private source with filename ``abcdefghij.jpg.150x150.jpg``, and then they try to reach the full-resolution image by simply cutting off the ``.150x150.jpg`` from the URL, they will be denied access.

Here's how it works: an S3 image is served with extra URL arguments after the filename, namely ``Signature=<letters and numbers>``, ``Expires=<number>``, and ``AWSAccessKeyId=<letters and numbers>``. The Signature in particular is generated by S3 during the website request, and is the key that allows the user to read the image. The Signature only works for serving that particular file until that particular Expires time (``django-storages`` makes it expire in 1 hour by default).

Note that although the AWS access key ID is exposed in the URL, it's not particularly a security issue, since an attacker cannot do anything unless they have the secret key as well. (`Link <http://stackoverflow.com/questions/7678835/how-secure-are-amazon-aws-access-keys>`__)

One potential security hole is the fact that ``HTTP_REFERER`` can be set by the web client. Most web clients provide valid referers, so it would take a reasonably focused snooper to take advantage of the security hole. Still, there are ways of restricting access further that could be implemented, such as using CloudFront and CNAMEs. See the comments in `this thread <http://stackoverflow.com/a/11525941/>`__.

See `this blog post <https://aws.amazon.com/blogs/security/iam-policies-and-bucket-policies-and-acls-oh-my-controlling-access-to-s3-resources/>`__ for info on bucket policies, `this docs page <http://docs.aws.amazon.com/AmazonS3/latest/dev/manage-acls-using-console.html>`__ for info on ACLs, and `this docs page <http://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html#example-bucket-policies-use-case-4>`__ for the referer check.


.. _sync_between_s3_buckets:

Syncing media from an S3 bucket to another S3 bucket
----------------------------------------------------

- *Staging server*
- *Alpha to beta server migration*

From an EC2 instance, simply run: ``aws s3 sync s3://<source bucket> s3://<destination bucket>``


.. _sync_filesystem_to_s3:

Syncing media from a server filesystem to S3
--------------------------------------------

- *Alpha to beta server migration*

SSH into an EC2 instance. Mount the CoralNet alpha server's filesystem using SSHFS.

- ``sudo apt-get install sshfs``
- ``sudo mkdir /mnt/cnalpha``
- ``sudo sshfs <username>@<alpha server host>/ /mnt/cnalpha`` to mount the root of the alpha server's filesystem at ``/mnt/cnalpha``.

Ensure the :ref:`AWS command line interface is installed <aws_cli_install>` on the EC2 instance.

You can sync small directories with the ``aws s3 sync`` command. For example: ``sudo aws s3 sync /mnt/cnalpha/path/to/media/label_thumbnails s3://<bucket-name>/media/labels``

Unfortunately, the ``aws s3 sync`` command seems to hang without transferring anything when it comes to large directories. (`Related GitHub issue <https://github.com/aws/aws-cli/issues/1775>`__)
Instead, use the ``scripts/s3_sync.py`` script in our repository to transfer the files. For example: ``sudo python path/to/s3_sync.py /mnt/cnalpha/path/to/media/data/original s3://<bucket-name>/media/images``. This script basically loops over the files and copies them one by one using ``aws s3 cp``.

The script has a ``--filter`` option that allows you to try transferring just a subset of images. For example, to transfer all files whose filenames start with ``00``, run: ``sudo python path/to/s3_sync.py <src> <dest> --filter "00.*"``

The process can be run in the background, and should not be interrupted even if you close your SSH session (despite SSHFS being used). When finished, a summary .txt file should be written, so you can see the number of files copied, time elapsed, etc. For us, the transfer of 1.2 TB of 600k image files would take about 15.5 days.